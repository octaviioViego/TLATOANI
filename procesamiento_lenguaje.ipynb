{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc2c0d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Importaciones\"\"\"\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk import word_tokenize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c77b3bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de ejemplos de entrenamiento\n",
      "klass\n",
      "0    6588\n",
      "1    3812\n",
      "Name: count, dtype: int64\n",
      "['En los cuentos de Disney el \"Y fueron felices para siempre.\" nunca explica si fueron juntos o por separado.'\n",
      " 'Típico: mirar el celular cuando no quieres saludar a alguien'\n",
      " '—¡¿Me estas engañando con otra?! —Obvio que no, amor. —¡¿Y ESE CALZÓN ROJO EN TU COCHE?! —Está bien, tengo que confesarlo...¡SOY SUPERMAN!'\n",
      " ...\n",
      " '—¿Tienes Wi-Fi? —Claro. —¿Cuál es la clave? —Tener dinero y pagarlo.'\n",
      " '|| diría que puede ir con Freya mientras.'\n",
      " 'Tracer. . . —Murmura con su fresco acento francés.—']\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Carga de datos\"\"\"\n",
    "#cargar los datos\n",
    "def read_dataset():\n",
    "    url_dataset = \"./dataset/dataset_humor_train.json\"\n",
    "    dataset = pd.read_json(url_dataset, lines=True)\n",
    "    #conteo de clases\n",
    "    print(\"Total de ejemplos de entrenamiento\")\n",
    "    print(dataset.klass.value_counts())\n",
    "    # Extracción de los textos en arreglos de numpy\n",
    "    X = dataset['text'].to_numpy()\n",
    "    # Extracción de las etiquetas o clases de entrenamiento\n",
    "    Y = dataset['klass'].to_numpy()\n",
    "\n",
    "    ID = dataset['id'].to_numpy()\n",
    "    return X,Y , ID\n",
    "\n",
    "X , Y , id = read_dataset()\n",
    "print(id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9ac961d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Normalización de datos\"\"\"\n",
    "# TODO: Definir las funciones de preprocesamiento de texto vinculadas al proceso de creación de la matriz \n",
    "# Documeno-Término creada con TfidfVectorizer.\n",
    "def matriz_tfidfVectorizer(X_train, X_val):\n",
    "\n",
    "    _STOPWORDS = stopwords.words(\"spanish\")  # agregar más palabras a esta lista si es necesario\n",
    "\n",
    "    # Normalización del texto\n",
    "\n",
    "    import unicodedata\n",
    "    import re\n",
    "    PUNCTUACTION = \";:,.\\\\-\\\"'/\"\n",
    "    SYMBOLS = \"()[]¿?¡!{}~<>|\"\n",
    "    NUMBERS= \"0123456789\"\n",
    "    SKIP_SYMBOLS = set(PUNCTUACTION + SYMBOLS)\n",
    "    SKIP_SYMBOLS_AND_SPACES = set(PUNCTUACTION + SYMBOLS + '\\t\\n\\r ')\n",
    "\n",
    "    def normaliza_texto(input_str,\n",
    "                        punct=False,\n",
    "                        accents=False,\n",
    "                        num=False,\n",
    "                        max_dup=2):\n",
    "        \"\"\"\n",
    "            punct=False (elimina la puntuación, True deja intacta la puntuación)\n",
    "            accents=False (elimina los acentos, True deja intactos los acentos)\n",
    "            num= False (elimina los números, True deja intactos los acentos)\n",
    "            max_dup=2 (número máximo de símbolos duplicados de forma consecutiva, rrrrr => rr)\n",
    "        \"\"\"\n",
    "        \n",
    "        nfkd_f = unicodedata.normalize('NFKD', input_str)\n",
    "        n_str = []\n",
    "        c_prev = ''\n",
    "        cc_prev = 0\n",
    "        for c in nfkd_f:\n",
    "            if not num:\n",
    "                if c in NUMBERS:\n",
    "                    continue\n",
    "            if not punct:\n",
    "                if c in SKIP_SYMBOLS:\n",
    "                    continue\n",
    "            if not accents and unicodedata.combining(c):\n",
    "                continue\n",
    "            if c_prev == c:\n",
    "                cc_prev += 1\n",
    "                if cc_prev >= max_dup:\n",
    "                    continue\n",
    "            else:\n",
    "                cc_prev = 0\n",
    "            n_str.append(c)\n",
    "            c_prev = c\n",
    "        texto = unicodedata.normalize('NFKD', \"\".join(n_str))\n",
    "        texto = re.sub(r'(\\s)+', r' ', texto.strip(), flags=re.IGNORECASE)\n",
    "        return texto\n",
    "\n",
    "\n",
    "    # Preprocesamiento personalizado \n",
    "    def mi_preprocesamiento(texto):\n",
    "        #convierte a minúsculas el texto antes de normalizar\n",
    "        tokens = word_tokenize(texto.lower())\n",
    "        texto = \" \".join(tokens)\n",
    "        texto = normaliza_texto(texto)\n",
    "        return texto\n",
    "        \n",
    "    # Tokenizador personalizado \n",
    "    def mi_tokenizador(texto):\n",
    "        # Elimina stopwords: palabras que no se consideran de contenido y que no agregan valor semántico al texto\n",
    "        #print(\"antes: \", texto)\n",
    "        texto = [t for t in texto.split() if t not in _STOPWORDS]\n",
    "        #print(\"después:\",texto)\n",
    "        return texto\n",
    "\n",
    "    # TODO: Crear la matriz Documento-Término con el dataset de entrenamiento: tfidfVectorizer\n",
    "\n",
    "    vec_tfidf = TfidfVectorizer(analyzer=\"word\", preprocessor=mi_preprocesamiento, tokenizer=mi_tokenizador,  ngram_range=(1,1))\n",
    "    X_train_tfidf = vec_tfidf.fit_transform(X_train)\n",
    "\n",
    "    # Convertir a matriz densa de tipo de dato float32 (tipo de dato por default en Pytorch)\n",
    "    X_train_tfidf = X_train_tfidf.toarray().astype(np.float32)\n",
    "\n",
    "    # Tranforma los datos de validación al espacio de representación del entrenamiento\n",
    "    X_val_tfidf = vec_tfidf.transform(X_val)\n",
    "\n",
    "    # Convertir a matriz densa de tipo de dato float32 (tipo de dato por default en Pytorch)\n",
    "    X_val_tfidf = X_val_tfidf.toarray().astype(np.float32)\n",
    "\n",
    "    return X_train_tfidf, X_val_tfidf, vec_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7dc8fd88",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Traduccion de texto a lenguaje maquina (LabelEncoder)\"\"\"\n",
    "# TODO: Codificar las etiquetas de los datos a una forma categórica numérica: LabelEncoder.\n",
    "def encode_labels(Y):\n",
    "\n",
    "    le = LabelEncoder()\n",
    "    # Normalizar las etiquetas a una codificación ordinal para entrada del clasificador\n",
    "    Y_encoded = le.fit_transform(Y)\n",
    "    print(\"Clases:\")\n",
    "    print(le.classes_)\n",
    "    print(\"Clases codificadas:\")\n",
    "    print(le.transform(le.classes_))\n",
    "\n",
    "    return Y_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27d112e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Generar cunjuntos de datos del dataset\"\"\"\n",
    "\n",
    "def dataset_div(X,Y_encoded):\n",
    "    # TODO: Dividir el conjunto de datos en conjunto de entrenamiento (80%) y conjunto de pruebas (20%)\n",
    "\n",
    "\n",
    "    X_train, X_test, Y_train, Y_test =  train_test_split(X, Y_encoded, test_size=0.2, stratify=Y_encoded, random_state=42)\n",
    "\n",
    "    # Divide el conjunto de entrenamiento en:  entrenamiento (90%) y validación (10%)\n",
    "    X_train, X_val, Y_train, Y_val =  train_test_split(X_train, Y_train, test_size=0.1, stratify=Y_train, random_state=42)\n",
    "\n",
    "    # Regresa primero los train y después los test\n",
    "    data_list_train = [X_train, X_val, Y_train, Y_val]\n",
    "    data_list_test = [X_test, Y_test]\n",
    "    \n",
    "    return data_list_train, data_list_test \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2227343c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Crear mini-batches\"\"\"\n",
    "\n",
    "# Crear minibatches en PyTorch usando DataLoader\n",
    "def create_minibatches(X, Y, batch_size):\n",
    "    # Recibe los documentos en X y las etiquetas en Y\n",
    "    dataset = TensorDataset(X, Y) # Cargar los datos en un dataset de tensores\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    # loader = DataLoader(dataset, batch_size=batch_size)\n",
    "    return loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ccc29fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"codificasión de la salida onehot\"\"\"\n",
    "\n",
    "def salida_onehot(Y_train,Y_test,Y_val,NUM_CLASSES = 2):\n",
    "    \n",
    "    # Codificación de la salida onehot\n",
    "    Y_train_one_hot = nn.functional.one_hot(torch.from_numpy(Y_train), num_classes=NUM_CLASSES).float()\n",
    "    Y_test_one_hot = nn.functional.one_hot(torch.from_numpy(Y_test), num_classes=NUM_CLASSES).float()\n",
    "    Y_val_one_hot = nn.functional.one_hot(torch.from_numpy(Y_val), num_classes=NUM_CLASSES).float()\n",
    "    \n",
    "    return Y_train_one_hot, Y_test_one_hot, Y_val_one_hot  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2259e1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Definicion de la arquitectura\"\"\"\n",
    "\n",
    "# Definir la red neuronal en PyTorch heredando de la clase base de Redes Neuronales: Module\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super().__init__()\n",
    "        # Definimos la normalizacion de los minibatches\n",
    "        self.bn1 = nn.BatchNorm1d(256)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.bn3 = nn.BatchNorm1d(64)\n",
    "        self.bn4 = nn.BatchNorm1d(32)\n",
    "        self.dropout = nn.Dropout(p=0.3)\n",
    "        #self.do = nn.Dropout()\n",
    "\n",
    "        # Definición de capas, funciones de activación e inicialización de pesos\n",
    "        input_size_h1 = 256\n",
    "        input_size_h2 = 128\n",
    "        input_size_h3 = 64\n",
    "        input_size_h4 = 32\n",
    "        \n",
    "\n",
    "        self.fc1 = nn.Linear(input_size, input_size_h1)\n",
    "        # PReLU tiene parámetros aprendibles: Se recomienda una función de activación independiente por capa\n",
    "        self.act1= nn.PReLU()\n",
    "\n",
    "        self.fc2 = nn.Linear(input_size_h1, input_size_h2)\n",
    "        # PReLU tiene parámetros aprendibles: Se recomienda una función de activación independiente por capa\n",
    "        self.act2= nn.PReLU()\n",
    "\n",
    "        self.fc3 = nn.Linear(input_size_h2, input_size_h3)\n",
    "        # PReLU tiene parámetros aprendibles: Se recomienda una función de activación independiente por capa\n",
    "        self.act3= nn.PReLU()\n",
    "\n",
    "        self.fc4 = nn.Linear(input_size_h3, input_size_h4)\n",
    "        # PReLU tiene parámetros aprendibles: Se recomienda una función de activación independiente por capa\n",
    "        self.act4= nn.PReLU()\n",
    "\n",
    "\n",
    "        # Esta es la salida\n",
    "        self.output = nn.Linear(input_size_h4, output_size)\n",
    "        \n",
    "        nn.init.xavier_uniform_(self.fc1.weight)\n",
    "        nn.init.xavier_uniform_(self.fc2.weight)\n",
    "        nn.init.xavier_uniform_(self.fc3.weight)\n",
    "        nn.init.xavier_uniform_(self.fc3.weight)\n",
    "        nn.init.xavier_uniform_(self.output.weight)\n",
    "\n",
    "        if self.fc1.bias is not None:\n",
    "            nn.init.zeros_(self.fc1.bias)\n",
    "        if self.fc2.bias is not None:\n",
    "            nn.init.zeros_(self.fc2.bias)\n",
    "        if self.fc3.bias is not None:\n",
    "            nn.init.zeros_(self.fc3.bias)\n",
    "        if self.fc4.bias is not None:\n",
    "            nn.init.zeros_(self.fc4.bias)                \n",
    "        if self.output.bias is not None:\n",
    "            nn.init.zeros_(self.output.bias)        \n",
    "\n",
    "    \n",
    "    def forward(self, X):\n",
    "        # Definición del orden de conexión de las capas y aplición de las funciones de activación\n",
    "        x = self.fc1(X)\n",
    "        x = self.bn1(x) #<-------- Aquí\n",
    "        x = self.dropout(x)\n",
    "        x = self.act1(x)\n",
    "        \n",
    "        x = self.fc2(x)\n",
    "        x = self.bn2(x) #<-------- Aquí \n",
    "        x = self.dropout(x)\n",
    "        x = self.act2(x)\n",
    "        \n",
    "        x = self.fc3(x)\n",
    "        x = self.bn3(x) #<-------- Aquí \n",
    "        x = self.dropout(x)\n",
    "        x = self.act3(x)\n",
    "\n",
    "        x = self.fc4(x)\n",
    "        x = self.bn4(x) #<-------- Aquí\n",
    "        x = self.dropout(x) \n",
    "        x = self.act4(x)\n",
    "\n",
    "        x = self.output(x)\n",
    "        # Nota la última capa de salida 'output' no se activa debido a que CrossEntropyLoss usa LogSoftmax internamente. \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6505d655",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Entrenamiento de la red neuronal\"\"\"\n",
    "\n",
    "def train_red_neuronal(X_train_tfidf,X_val_tfidf,output_size=2,epochs=50,learning_rate=0.01,batch_size=128):\n",
    "    # Establecer los parámetros de la red\n",
    "\n",
    "    # Parámetros de la red\n",
    "    input_size =  X_train_tfidf.shape[1]\n",
    "\n",
    "    #output_size = 2   # 2 clases\n",
    "\n",
    "    #epochs = 50 # variar el número de épocas, para probar que funciona la programación \n",
    "                    # solo usar 2 épocas, para entrenamiento total usar por ejemplo 1000 épocas\n",
    "    #learning_rate = 0.01 # Generalmente se usan learning rate pequeños (0.001), \n",
    "\n",
    "    # Se recomiendan tamaños de batch_size potencias de 2: 16, 32, 64, 128, 256\n",
    "    # Entre mayor el número más cantidad de memoria se requiere para el procesamiento\n",
    "    #batch_size = 128 # definir el tamaño del lote de procesamiento \n",
    "\n",
    "\n",
    "    # TODO: Convertir los datos de entrenamiento y etiquetas a tensores  de PyTorch\n",
    "\n",
    "    X_train_t = torch.from_numpy(X_train_tfidf)\n",
    "    Y_train_t = Y_train_one_hot\n",
    "\n",
    "    X_val_t = torch.from_numpy(X_val_tfidf)\n",
    "\n",
    "    # Crear la red\n",
    "    model = MLP(input_size, output_size)\n",
    "\n",
    "    # Definir la función de pérdida\n",
    "    # Mean Square Error (MSE)\n",
    "    # criterion = nn.MSELoss()\n",
    "    # criterion = nn.BCELoss()\n",
    "    weights = torch.tensor([2.5, 1.0]) \n",
    "    criterion = nn.CrossEntropyLoss(weight=weights) \n",
    "\n",
    "    # Definir el optimizador\n",
    "    #Parámetros del optimizador: parámetros del modelo y learning rate \n",
    "    # Stochastic Gradient Descent (SGD)\n",
    "    # optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # Entrenamiento\n",
    "    print(\"Iniciando entrenamiento en PyTorch\")\n",
    "\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # Poner el modelo en modo de entrenamiento\n",
    "        model.train()  \n",
    "        lossTotal = 0\n",
    "        #definir el batch_size\n",
    "        dataloader = create_minibatches(X_train_t, Y_train_t, batch_size=batch_size)\n",
    "\n",
    "        for X_tr, y_tr in dataloader:\n",
    "            # inicializar los gradientes en cero para cada época\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Propagación hacia adelante\n",
    "            y_pred = model(X_tr)  #invoca al método forward de la clase MLP\n",
    "            # Calcular el error MSE\n",
    "            loss = criterion(y_pred, y_tr)\n",
    "            #Acumular el error \n",
    "            lossTotal += loss.item()\n",
    "            \n",
    "            # Propagación hacia atrás: cálculo de los gradientes de los pesos y bias\n",
    "            loss.backward()\n",
    "            \n",
    "            # actualización de los pesos: regla de actualización basado en el gradiente:\n",
    "            #  W = W - learning_rate * dE/dW\n",
    "            optimizer.step()\n",
    "            if np.random.random() < 0.1:\n",
    "                print(f\"Batch Error : {loss.item()}\")\n",
    "\n",
    "        print(f\"Época {epoch+1}/{epochs}, Pérdida: {lossTotal/len(dataloader)}\")\n",
    "\n",
    "        # Evalúa el modelo con el conjunto de validación\n",
    "        model.eval()  # Establecer el modo del modelo a \"evaluación\"\n",
    "        with torch.no_grad():  # No  calcular gradientes \n",
    "            y_pred = model(X_val_t)\n",
    "            # Aplica softmax para obtener las probabilidades en la evaluación\n",
    "            y_pred = torch.softmax(y_pred, dim=1)\n",
    "            # Obtiene una única clase, la más probable\n",
    "            y_pred = torch.argmax(y_pred, dim=1)        \n",
    "            print(f\"Época {epoch+1}/{epochs}\")\n",
    "            print(\"P=\", precision_score(Y_val, y_pred, average='macro'))\n",
    "            print(\"R=\", recall_score(Y_val, y_pred, average='macro'))\n",
    "            print(\"F1=\", f1_score(Y_val, y_pred, average='macro'))\n",
    "            print(\"Acc=\", accuracy_score(Y_val, y_pred))\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f0e6db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Evaluación\"\"\"\n",
    "\"\"\"Aquí en está función juntamos la predicción de datos y la evaluación\"\"\"\n",
    "\n",
    "def evaluacion(X_test,vec_tfidf,Y_test,model):\n",
    "    \n",
    "    # TODO: Transformar el dataset de test con los mismos preprocesamientos y al  espacio de \n",
    "    # representación vectorial que el modelo entrenado, es decir, al espacio de la matriz TFIDF\n",
    "\n",
    "    # Convertir los datos de prueba a tensores de PyTorch\n",
    "\n",
    "    X_test_tfidf = vec_tfidf.transform(X_test)\n",
    "\n",
    "    # Convertir a matriz densa de tipo de dato float32 (tipo de dato por default en Pytorch)\n",
    "    X_test_tfidf = X_test_tfidf.toarray().astype(np.float32)\n",
    "    X_t = torch.from_numpy(X_test_tfidf)\n",
    "\n",
    "    # Desactivar el comportamiento de modo de  entrenamiento: por ejemplo, capas como Dropout\n",
    "    model.eval()  # Establecer el modo del modelo a \"evaluación\"\n",
    "\n",
    "    with torch.no_grad():  # No  calcular gradientes \n",
    "        y_pred_test= model(X_t)\n",
    "\n",
    "    # y_test_pred contiene las predicciones\n",
    "\n",
    "    # Obtener la clase real\n",
    "    y_pred_test = torch.argmax(y_pred_test, dim=1)\n",
    "\n",
    "    print(y_pred_test)\n",
    "\n",
    "    # TODO: Evaluar el modelo con las predicciones obtenidas y las etiquetas esperadas: \n",
    "    # classification_report y  matriz de confusión (métricas Precisión, Recall, F1-measaure, Accuracy)\n",
    "\n",
    "\n",
    "    print(confusion_matrix(Y_test, y_pred_test))\n",
    "    print(classification_report(Y_test, y_pred_test, digits=4, zero_division='warn'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "351a96cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de ejemplos de entrenamiento\n",
      "klass\n",
      "nonaggressive    3655\n",
      "aggressive       1477\n",
      "Name: count, dtype: int64\n",
      "Clases:\n",
      "['aggressive' 'nonaggressive']\n",
      "Clases codificadas:\n",
      "[0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/octaviio/anaconda3/envs/RNA/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando entrenamiento en PyTorch\n",
      "Batch Error : 1.1027387380599976\n",
      "Época 1/150, Pérdida: 0.927020802580077\n",
      "Época 1/150\n",
      "P= 0.7165672651254305\n",
      "R= 0.7037513738647538\n",
      "F1= 0.7093243997766611\n",
      "Acc= 0.7688564476885644\n",
      "Batch Error : 0.2581704556941986\n",
      "Batch Error : 0.19774001836776733\n",
      "Batch Error : 0.32691633701324463\n",
      "Época 2/150, Pérdida: 0.2933638185776513\n",
      "Época 2/150\n",
      "P= 0.6728735632183909\n",
      "R= 0.695754034823856\n",
      "F1= 0.678888948758015\n",
      "Acc= 0.7177615571776156\n",
      "Batch Error : 0.04677027091383934\n",
      "Batch Error : 0.0955025926232338\n",
      "Batch Error : 0.05184469744563103\n",
      "Batch Error : 0.033561524003744125\n",
      "Época 3/150, Pérdida: 0.07690962802233367\n",
      "Época 3/150\n",
      "P= 0.6755366977632911\n",
      "R= 0.6806849077341355\n",
      "F1= 0.6778996865203761\n",
      "Acc= 0.732360097323601\n",
      "Batch Error : 0.05072338879108429\n",
      "Batch Error : 0.035411592572927475\n",
      "Batch Error : 0.03281572088599205\n",
      "Época 4/150, Pérdida: 0.044022180300591324\n",
      "Época 4/150\n",
      "P= 0.6854090885803577\n",
      "R= 0.7093480650199572\n",
      "F1= 0.6921348314606741\n",
      "Acc= 0.7299270072992701\n",
      "Batch Error : 0.014101319015026093\n",
      "Batch Error : 0.033454883843660355\n",
      "Época 5/150, Pérdida: 0.030546251443567974\n",
      "Época 5/150\n",
      "P= 0.6870446533490011\n",
      "R= 0.6841557239544166\n",
      "F1= 0.6855439859513105\n",
      "Acc= 0.7445255474452555\n",
      "Batch Error : 0.04697605222463608\n",
      "Batch Error : 0.004510436672717333\n",
      "Batch Error : 0.025551624596118927\n",
      "Batch Error : 0.023271622136235237\n",
      "Época 6/150, Pérdida: 0.01664447875950357\n",
      "Época 6/150\n",
      "P= 0.6823849191323633\n",
      "R= 0.6950454098455486\n",
      "F1= 0.6874219409577104\n",
      "Acc= 0.7347931873479319\n",
      "Batch Error : 0.04058011621236801\n",
      "Batch Error : 0.007425135467201471\n",
      "Época 7/150, Pérdida: 0.01565798635771177\n",
      "Época 7/150\n",
      "P= 0.6788321167883211\n",
      "R= 0.6941632440562273\n",
      "F1= 0.6844693432928727\n",
      "Acc= 0.7299270072992701\n",
      "Batch Error : 0.016482172533869743\n",
      "Época 8/150, Pérdida: 0.0201002485801241\n",
      "Época 8/150\n",
      "P= 0.6700802139037433\n",
      "R= 0.6839821831434025\n",
      "F1= 0.6752384385050461\n",
      "Acc= 0.7226277372262774\n",
      "Batch Error : 0.005830888636410236\n",
      "Batch Error : 0.015868699178099632\n",
      "Batch Error : 0.006597922649234533\n",
      "Batch Error : 0.13524000346660614\n",
      "Época 9/150, Pérdida: 0.03259218531532277\n",
      "Época 9/150\n",
      "P= 0.682075171205606\n",
      "R= 0.6984005321918205\n",
      "F1= 0.6879831051236749\n",
      "Acc= 0.732360097323601\n",
      "Batch Error : 0.0348721481859684\n",
      "Época 10/150, Pérdida: 0.041036367504696906\n",
      "Época 10/150\n",
      "P= 0.6560226673695309\n",
      "R= 0.6712124717996182\n",
      "F1= 0.661058881741712\n",
      "Acc= 0.708029197080292\n",
      "Batch Error : 0.021040180698037148\n",
      "Batch Error : 0.06147918105125427\n",
      "Batch Error : 0.02372290939092636\n",
      "Batch Error : 0.148530974984169\n",
      "Batch Error : 0.10743016004562378\n",
      "Época 11/150, Pérdida: 0.04624319888233881\n",
      "Época 11/150\n",
      "P= 0.6628965922444183\n",
      "R= 0.6603806328454909\n",
      "F1= 0.6615854324999817\n",
      "Acc= 0.7250608272506083\n",
      "Batch Error : 0.012083186767995358\n",
      "Época 12/150, Pérdida: 0.030691494651395698\n",
      "Época 12/150\n",
      "P= 0.6697622794200292\n",
      "R= 0.674741134956904\n",
      "F1= 0.6720433171843829\n",
      "Acc= 0.7274939172749392\n",
      "Época 13/150, Pérdida: 0.036224385683328426\n",
      "Época 13/150\n",
      "P= 0.6735500162919518\n",
      "R= 0.684864348932724\n",
      "F1= 0.6780979020979021\n",
      "Acc= 0.7274939172749392\n",
      "Batch Error : 0.017130861058831215\n",
      "Batch Error : 0.08991239219903946\n",
      "Batch Error : 0.02232498675584793\n",
      "Época 14/150, Pérdida: 0.012796552060974827\n",
      "Época 14/150\n",
      "P= 0.6781960032849712\n",
      "R= 0.6882773182160005\n",
      "F1= 0.6824069911206024\n",
      "Acc= 0.732360097323601\n",
      "Batch Error : 0.0017470007296651602\n",
      "Batch Error : 0.0018937548156827688\n",
      "Batch Error : 0.000971034518443048\n",
      "Época 15/150, Pérdida: 0.005667347677758542\n",
      "Época 15/150\n",
      "P= 0.6831402293358815\n",
      "R= 0.6773876323248684\n",
      "F1= 0.6800381903642774\n",
      "Acc= 0.7420924574209246\n",
      "Batch Error : 0.0029760580509901047\n",
      "Batch Error : 0.009535570628941059\n",
      "Batch Error : 0.006605225149542093\n",
      "Época 16/150, Pérdida: 0.003008868882496809\n",
      "Época 16/150\n",
      "P= 0.6713593616414932\n",
      "R= 0.6739168161045872\n",
      "F1= 0.6725851712036286\n",
      "Acc= 0.7299270072992701\n",
      "Época 17/150, Pérdida: 0.0017589678674743607\n",
      "Época 17/150\n",
      "P= 0.6688694764308809\n",
      "R= 0.6722103314629491\n",
      "F1= 0.6704467353951891\n",
      "Acc= 0.7274939172749392\n",
      "Batch Error : 0.0016593942418694496\n",
      "Batch Error : 0.00034350878559052944\n",
      "Batch Error : 0.0008697512676008046\n",
      "Época 18/150, Pérdida: 0.0009392801735445793\n",
      "Época 18/150\n",
      "P= 0.6823558190399448\n",
      "R= 0.6832735581650952\n",
      "F1= 0.682808611922536\n",
      "Acc= 0.7396593673965937\n",
      "Batch Error : 0.003976963926106691\n",
      "Época 19/150, Pérdida: 0.0009058271198541504\n",
      "Época 19/150\n",
      "P= 0.6756933542647828\n",
      "R= 0.6747989818939087\n",
      "F1= 0.6752401319366415\n",
      "Acc= 0.7347931873479319\n",
      "Batch Error : 0.0001480636710766703\n",
      "Batch Error : 0.001052668085321784\n",
      "Batch Error : 0.00011464995623100549\n",
      "Época 20/150, Pérdida: 0.0006758232509661145\n",
      "Época 20/150\n",
      "P= 0.6879369007114136\n",
      "R= 0.6757389946202348\n",
      "F1= 0.6809006211180124\n",
      "Acc= 0.7469586374695864\n",
      "Batch Error : 0.00022956840984988958\n",
      "Época 21/150, Pérdida: 0.0015867450351050075\n",
      "Época 21/150\n",
      "P= 0.6776537302853092\n",
      "R= 0.6739746630415919\n",
      "F1= 0.6757159555815313\n",
      "Acc= 0.7372262773722628\n",
      "Batch Error : 0.00020949615282006562\n",
      "Época 22/150, Pérdida: 0.0030591176079630307\n",
      "Época 22/150\n",
      "P= 0.6792028677319399\n",
      "R= 0.6706195406953201\n",
      "F1= 0.6744012142301854\n",
      "Acc= 0.7396593673965937\n",
      "Batch Error : 0.00033462123246863484\n",
      "Batch Error : 0.0042134360410273075\n",
      "Batch Error : 0.0004799330490641296\n",
      "Batch Error : 0.0001340181042905897\n",
      "Batch Error : 0.00032093352638185024\n",
      "Época 23/150, Pérdida: 0.0005733544483142584\n",
      "Época 23/150\n",
      "P= 0.679036270029502\n",
      "R= 0.679036270029502\n",
      "F1= 0.679036270029502\n",
      "Acc= 0.7372262773722628\n",
      "Batch Error : 0.00022803775209467858\n",
      "Batch Error : 0.00018028162594418973\n",
      "Época 24/150, Pérdida: 0.0008157522122552298\n",
      "Época 24/150\n",
      "P= 0.6730924972522705\n",
      "R= 0.6730924972522705\n",
      "F1= 0.6730924972522705\n",
      "Acc= 0.732360097323601\n",
      "Batch Error : 0.00030152173712849617\n",
      "Batch Error : 0.00010684176959330216\n",
      "Batch Error : 9.42752230912447e-05\n",
      "Época 25/150, Pérdida: 0.000502308541462267\n",
      "Época 25/150\n",
      "P= 0.684547152194211\n",
      "R= 0.6715017064846416\n",
      "F1= 0.6769279142367324\n",
      "Acc= 0.7445255474452555\n",
      "Batch Error : 0.0018691499717533588\n",
      "Batch Error : 0.0004375220451038331\n",
      "Época 26/150, Pérdida: 0.0013026632693473748\n",
      "Época 26/150\n",
      "P= 0.6776730551002396\n",
      "R= 0.6630271302134552\n",
      "F1= 0.6689002492075802\n",
      "Acc= 0.7396593673965937\n",
      "Época 27/150, Pérdida: 0.0009091722948079254\n",
      "Época 27/150\n",
      "P= 0.6697622794200292\n",
      "R= 0.674741134956904\n",
      "F1= 0.6720433171843829\n",
      "Acc= 0.7274939172749392\n",
      "Batch Error : 0.00013304110325407237\n",
      "Batch Error : 0.00035556391230784357\n",
      "Batch Error : 0.0005445863353088498\n",
      "Batch Error : 0.0001176721925730817\n",
      "Batch Error : 0.00015102376346476376\n",
      "Batch Error : 3.5982408007839695e-05\n",
      "Época 28/150, Pérdida: 0.0010180377866445584\n",
      "Época 28/150\n",
      "P= 0.6673426573426573\n",
      "R= 0.6730346503152658\n",
      "F1= 0.6699076739376106\n",
      "Acc= 0.7250608272506083\n",
      "Batch Error : 0.0001015623493003659\n",
      "Batch Error : 3.19575410685502e-05\n",
      "Época 29/150, Pérdida: 0.0012838037014419037\n",
      "Época 29/150\n",
      "P= 0.6810076380728554\n",
      "R= 0.6782119511771851\n",
      "F1= 0.6795543475884783\n",
      "Acc= 0.7396593673965937\n",
      "Batch Error : 0.0004262377042323351\n",
      "Batch Error : 0.00331665831618011\n",
      "Época 30/150, Pérdida: 0.0018581434413386761\n",
      "Época 30/150\n",
      "P= 0.6786614608952287\n",
      "R= 0.6680887372013652\n",
      "F1= 0.6726074818537131\n",
      "Acc= 0.7396593673965937\n",
      "Batch Error : 0.0002025560097536072\n",
      "Batch Error : 0.0006840613787062466\n",
      "Batch Error : 4.9327692977385595e-05\n",
      "Batch Error : 0.025569645687937737\n",
      "Batch Error : 0.004110957495868206\n",
      "Batch Error : 6.443729216698557e-05\n",
      "Época 31/150, Pérdida: 0.0027131990544399616\n",
      "Época 31/150\n",
      "P= 0.6807062630877594\n",
      "R= 0.6647336148550934\n",
      "F1= 0.6710510419812745\n",
      "Acc= 0.7420924574209246\n",
      "Batch Error : 0.00014592894876841456\n",
      "Batch Error : 0.0017610121285542846\n",
      "Batch Error : 7.574439950985834e-05\n",
      "Época 32/150, Pérdida: 0.010918871758145416\n",
      "Época 32/150\n",
      "P= 0.6606114498644986\n",
      "R= 0.6645600740440794\n",
      "F1= 0.6624434906192642\n",
      "Acc= 0.7201946472019465\n",
      "Batch Error : 0.06347549706697464\n",
      "Batch Error : 0.0041389018297195435\n",
      "Batch Error : 0.0013707519974559546\n",
      "Época 33/150, Pérdida: 0.0388655045455129\n",
      "Época 33/150\n",
      "P= 0.6810076380728554\n",
      "R= 0.6782119511771851\n",
      "F1= 0.6795543475884783\n",
      "Acc= 0.7396593673965937\n",
      "Batch Error : 0.05084626376628876\n",
      "Batch Error : 0.0066883983090519905\n",
      "Batch Error : 0.02358178235590458\n",
      "Época 34/150, Pérdida: 0.022824924427148854\n",
      "Época 34/150\n",
      "P= 0.6749706227967098\n",
      "R= 0.6722681783999538\n",
      "F1= 0.6735647092256462\n",
      "Acc= 0.7347931873479319\n",
      "Batch Error : 0.025724051520228386\n",
      "Batch Error : 0.020281847566366196\n",
      "Batch Error : 0.0015176450833678246\n",
      "Batch Error : 0.004314878489822149\n",
      "Batch Error : 0.026943588629364967\n",
      "Época 35/150, Pérdida: 0.015233783701691648\n",
      "Época 35/150\n",
      "P= 0.7012195121951219\n",
      "R= 0.7061664834846995\n",
      "F1= 0.7035373265438756\n",
      "Acc= 0.754257907542579\n",
      "Batch Error : 0.0088759521022439\n",
      "Batch Error : 0.024700991809368134\n",
      "Batch Error : 0.001863149693235755\n",
      "Batch Error : 0.007881349883973598\n",
      "Batch Error : 0.010173101909458637\n",
      "Época 36/150, Pérdida: 0.017788564786314964\n",
      "Época 36/150\n",
      "P= 0.6829588118374559\n",
      "R= 0.691690287499277\n",
      "F1= 0.6867378048780488\n",
      "Acc= 0.7372262773722628\n",
      "Época 37/150, Pérdida: 0.014477037501537466\n",
      "Época 37/150\n",
      "P= 0.6772157309774864\n",
      "R= 0.6798605888818188\n",
      "F1= 0.6784845374882479\n",
      "Acc= 0.7347931873479319\n",
      "Batch Error : 0.0007832323899492621\n",
      "Batch Error : 0.00136303820181638\n",
      "Batch Error : 0.0154736852273345\n",
      "Batch Error : 0.04294303432106972\n",
      "Época 38/150, Pérdida: 0.014312640012137527\n",
      "Época 38/150\n",
      "P= 0.6849800428067334\n",
      "R= 0.6849800428067334\n",
      "F1= 0.6849800428067334\n",
      "Acc= 0.7420924574209246\n",
      "Batch Error : 0.0025271810591220856\n",
      "Época 39/150, Pérdida: 0.007807713897160158\n",
      "Época 39/150\n",
      "P= 0.6967810801818787\n",
      "R= 0.705284317695378\n",
      "F1= 0.7005411523361511\n",
      "Acc= 0.7493917274939172\n",
      "Batch Error : 0.0004795159329660237\n",
      "Batch Error : 0.008929005824029446\n",
      "Batch Error : 0.00019811897072941065\n",
      "Época 40/150, Pérdida: 0.003638566306547326\n",
      "Época 40/150\n",
      "P= 0.6960839160839161\n",
      "R= 0.702753514201423\n",
      "F1= 0.6991193842086185\n",
      "Acc= 0.7493917274939172\n",
      "Batch Error : 0.00043537066085264087\n",
      "Batch Error : 0.001780024846084416\n",
      "Época 41/150, Pérdida: 0.004554128469016146\n",
      "Época 41/150\n",
      "P= 0.7023524254821741\n",
      "R= 0.7002805576444727\n",
      "F1= 0.7012907727193441\n",
      "Acc= 0.7566909975669099\n",
      "Batch Error : 0.007832048460841179\n",
      "Batch Error : 0.00012156720913480967\n",
      "Batch Error : 0.00019402752513997257\n",
      "Batch Error : 0.0010192819172516465\n",
      "Época 42/150, Pérdida: 0.005472157643515826\n",
      "Época 42/150\n",
      "P= 0.6950725431152478\n",
      "R= 0.7061086365476948\n",
      "F1= 0.6997302461503878\n",
      "Acc= 0.7469586374695864\n",
      "Batch Error : 0.0002363978564972058\n",
      "Batch Error : 0.0006129094399511814\n",
      "Batch Error : 0.0007492865552194417\n",
      "Batch Error : 0.00015242063091136515\n",
      "Época 43/150, Pérdida: 0.0010359487054741074\n",
      "Época 43/150\n",
      "P= 0.6926663031624865\n",
      "R= 0.7044021519060566\n",
      "F1= 0.6975335898568094\n",
      "Acc= 0.7445255474452555\n",
      "Batch Error : 0.00017215663683600724\n",
      "Batch Error : 0.00015026448818389326\n",
      "Época 44/150, Pérdida: 0.0008275613887737313\n",
      "Época 44/150\n",
      "P= 0.7064975776574522\n",
      "R= 0.709579452767976\n",
      "F1= 0.7079813689113444\n",
      "Acc= 0.7591240875912408\n",
      "Batch Error : 0.0001545678242109716\n",
      "Época 45/150, Pérdida: 0.0007407093701125443\n",
      "Época 45/150\n",
      "P= 0.6902899967416096\n",
      "R= 0.7026956672644183\n",
      "F1= 0.6953426573426573\n",
      "Acc= 0.7420924574209246\n",
      "Batch Error : 7.702821312705055e-05\n",
      "Batch Error : 0.0006848390330560505\n",
      "Batch Error : 0.003983072005212307\n",
      "Batch Error : 5.2032479288754985e-05\n",
      "Batch Error : 2.6011915906565264e-05\n",
      "Batch Error : 0.0003146334202028811\n",
      "Batch Error : 0.0020696157589554787\n",
      "Época 46/150, Pérdida: 0.00043201887406055527\n",
      "Época 46/150\n",
      "P= 0.6950725431152478\n",
      "R= 0.7061086365476948\n",
      "F1= 0.6997302461503878\n",
      "Acc= 0.7469586374695864\n",
      "Batch Error : 0.0002653677074704319\n",
      "Época 47/150, Pérdida: 0.0003892783396591328\n",
      "Época 47/150\n",
      "P= 0.7143629456458211\n",
      "R= 0.7121681031989355\n",
      "F1= 0.7132391418105704\n",
      "Acc= 0.7664233576642335\n",
      "Batch Error : 2.62633002421353e-05\n",
      "Época 48/150, Pérdida: 0.0002349291984313007\n",
      "Época 48/150\n",
      "P= 0.7070206639566397\n",
      "R= 0.7121102562619309\n",
      "F1= 0.7094078745331058\n",
      "Acc= 0.7591240875912408\n",
      "Batch Error : 1.1978881957475096e-05\n",
      "Batch Error : 3.1922732887323946e-05\n",
      "Época 49/150, Pérdida: 0.0003653028511978156\n",
      "Época 49/150\n",
      "P= 0.6967810801818787\n",
      "R= 0.705284317695378\n",
      "F1= 0.7005411523361511\n",
      "Acc= 0.7493917274939172\n",
      "Batch Error : 0.0004568494332488626\n",
      "Batch Error : 0.0006667682901024818\n",
      "Batch Error : 0.00012632847938220948\n",
      "Batch Error : 5.229567705100635e-06\n",
      "Batch Error : 6.736151408404112e-05\n",
      "Época 50/150, Pérdida: 0.0004975609872887837\n",
      "Época 50/150\n",
      "P= 0.7038402632026775\n",
      "R= 0.7078729681263377\n",
      "F1= 0.7057560137457045\n",
      "Acc= 0.7566909975669099\n",
      "Batch Error : 9.183699876302853e-05\n",
      "Batch Error : 7.69007601775229e-05\n",
      "Batch Error : 2.445771315251477e-05\n",
      "Batch Error : 1.7844173271441832e-05\n",
      "Época 51/150, Pérdida: 0.0002413310046920052\n",
      "Época 51/150\n",
      "P= 0.7012195121951219\n",
      "R= 0.7061664834846995\n",
      "F1= 0.7035373265438756\n",
      "Acc= 0.754257907542579\n",
      "Batch Error : 2.4702792870812118e-05\n",
      "Batch Error : 8.086101843218785e-06\n",
      "Batch Error : 5.650251478073187e-05\n",
      "Batch Error : 3.321575786685571e-05\n",
      "Época 52/150, Pérdida: 0.00012494366162705962\n",
      "Época 52/150\n",
      "P= 0.7050125313283209\n",
      "R= 0.7129345751142477\n",
      "F1= 0.7085767769016961\n",
      "Acc= 0.7566909975669099\n",
      "Batch Error : 8.738800534047186e-05\n",
      "Batch Error : 0.00394906522706151\n",
      "Época 53/150, Pérdida: 0.0003101742574691688\n",
      "Época 53/150\n",
      "P= 0.6986343711363381\n",
      "R= 0.7044599988430613\n",
      "F1= 0.7013251638643487\n",
      "Acc= 0.7518248175182481\n",
      "Batch Error : 5.158947897143662e-05\n",
      "Batch Error : 1.3924817721999716e-05\n",
      "Batch Error : 2.3046939531923272e-05\n",
      "Época 54/150, Pérdida: 5.6305823908713075e-05\n",
      "Época 54/150\n",
      "P= 0.7028113611384277\n",
      "R= 0.7028113611384277\n",
      "F1= 0.7028113611384277\n",
      "Acc= 0.7566909975669099\n",
      "Batch Error : 0.00016269501065835357\n",
      "Batch Error : 3.530090907588601e-05\n",
      "Batch Error : 0.000260991946561262\n",
      "Batch Error : 6.351189222186804e-05\n",
      "Batch Error : 2.913025309680961e-05\n",
      "Época 55/150, Pérdida: 9.129750375497428e-05\n",
      "Época 55/150\n",
      "P= 0.7028113611384277\n",
      "R= 0.7028113611384277\n",
      "F1= 0.7028113611384277\n",
      "Acc= 0.7566909975669099\n",
      "Batch Error : 1.0686258065106813e-05\n",
      "Batch Error : 0.0007495922036468983\n",
      "Batch Error : 1.3884266991226468e-05\n",
      "Batch Error : 1.127933956013294e-05\n",
      "Época 56/150, Pérdida: 0.00016224402826663147\n",
      "Época 56/150\n",
      "P= 0.7060118567975135\n",
      "R= 0.7070486492740209\n",
      "F1= 0.7065238558909446\n",
      "Acc= 0.7591240875912408\n",
      "Batch Error : 9.83329227892682e-05\n",
      "Batch Error : 8.459244781988673e-06\n",
      "Época 57/150, Pérdida: 4.985298450076792e-05\n",
      "Época 57/150\n",
      "P= 0.7055642769928485\n",
      "R= 0.7045178457800659\n",
      "F1= 0.7050346152452064\n",
      "Acc= 0.7591240875912408\n",
      "Batch Error : 5.304550086293602e-06\n",
      "Batch Error : 2.1264822862576693e-05\n",
      "Batch Error : 4.519833964877762e-05\n",
      "Época 58/150, Pérdida: 4.700566394384278e-05\n",
      "Época 58/150\n",
      "P= 0.709192439862543\n",
      "R= 0.7112859374096141\n",
      "F1= 0.7102135374697824\n",
      "Acc= 0.7615571776155717\n",
      "Batch Error : 1.010038613458164e-05\n",
      "Época 59/150, Pérdida: 4.6406576341817935e-05\n",
      "Época 59/150\n",
      "P= 0.7064975776574522\n",
      "R= 0.709579452767976\n",
      "F1= 0.7079813689113444\n",
      "Acc= 0.7591240875912408\n",
      "Batch Error : 2.0917397705488838e-05\n",
      "Batch Error : 6.38081746728858e-06\n",
      "Batch Error : 8.470849024888594e-06\n",
      "Batch Error : 3.524450448821881e-06\n",
      "Época 60/150, Pérdida: 4.7658093715905e-05\n",
      "Época 60/150\n",
      "P= 0.709192439862543\n",
      "R= 0.7112859374096141\n",
      "F1= 0.7102135374697824\n",
      "Acc= 0.7615571776155717\n",
      "Batch Error : 0.04895668104290962\n",
      "Época 61/150, Pérdida: 0.0017193506163070637\n",
      "Época 61/150\n",
      "P= 0.7106306306306307\n",
      "R= 0.7028692080754324\n",
      "F1= 0.7064220859076416\n",
      "Acc= 0.7639902676399026\n",
      "Batch Error : 9.011874681164045e-06\n",
      "Batch Error : 0.005425433162599802\n",
      "Batch Error : 0.0001214631920447573\n",
      "Época 62/150, Pérdida: 0.005116386264333038\n",
      "Época 62/150\n",
      "P= 0.6907400550148117\n",
      "R= 0.7085815931046451\n",
      "F1= 0.6971385282875935\n",
      "Acc= 0.7396593673965937\n",
      "Batch Error : 0.24208186566829681\n",
      "Batch Error : 0.0008055992075242102\n",
      "Batch Error : 0.02372601255774498\n",
      "Época 63/150, Pérdida: 0.025456267743469776\n",
      "Época 63/150\n",
      "P= 0.6982688113413305\n",
      "R= 0.710345924683288\n",
      "F1= 0.7032948548119178\n",
      "Acc= 0.7493917274939172\n",
      "Batch Error : 0.0018411715282127261\n",
      "Batch Error : 0.012870145961642265\n",
      "Época 64/150, Pérdida: 0.016748820145008284\n",
      "Época 64/150\n",
      "P= 0.694784838985466\n",
      "R= 0.697691907213513\n",
      "F1= 0.6961826363421059\n",
      "Acc= 0.7493917274939172\n",
      "Batch Error : 0.03380703553557396\n",
      "Época 65/150, Pérdida: 0.019354238803097015\n",
      "Época 65/150\n",
      "P= 0.6963471654003507\n",
      "R= 0.6943367848672413\n",
      "F1= 0.6953165881737311\n",
      "Acc= 0.7518248175182481\n",
      "Batch Error : 0.005482818000018597\n",
      "Batch Error : 0.00516657717525959\n",
      "Batch Error : 0.01055095437914133\n",
      "Batch Error : 0.1938527375459671\n",
      "Época 66/150, Pérdida: 0.015498469990140212\n",
      "Época 66/150\n",
      "P= 0.709192439862543\n",
      "R= 0.7112859374096141\n",
      "F1= 0.7102135374697824\n",
      "Acc= 0.7615571776155717\n",
      "Batch Error : 0.0330691859126091\n",
      "Batch Error : 0.009460396133363247\n",
      "Época 67/150, Pérdida: 0.04017170296644728\n",
      "Época 67/150\n",
      "P= 0.7022334177488011\n",
      "R= 0.7171140163128362\n",
      "F1= 0.7081453634085213\n",
      "Acc= 0.7518248175182481\n",
      "Batch Error : 0.005205091089010239\n",
      "Batch Error : 0.010024948045611382\n",
      "Batch Error : 0.11078592389822006\n",
      "Batch Error : 0.01013063546270132\n",
      "Batch Error : 0.012348233722150326\n",
      "Batch Error : 0.012253688648343086\n",
      "Batch Error : 0.006854284089058638\n",
      "Batch Error : 0.04006175324320793\n",
      "Época 68/150, Pérdida: 0.02132614323837233\n",
      "Época 68/150\n",
      "P= 0.7234868306296878\n",
      "R= 0.7223491641117603\n",
      "F1= 0.7229113052303454\n",
      "Acc= 0.7737226277372263\n",
      "Batch Error : 0.004859027918428183\n",
      "Batch Error : 0.002845685463398695\n",
      "Batch Error : 0.0007396953296847641\n",
      "Batch Error : 0.0011247319635003805\n",
      "Época 69/150, Pérdida: 0.004210931580144398\n",
      "Época 69/150\n",
      "P= 0.710174717368962\n",
      "R= 0.7247642737317059\n",
      "F1= 0.716098827108379\n",
      "Acc= 0.7591240875912408\n",
      "Batch Error : 0.00039738736813887954\n",
      "Batch Error : 0.00041541061364114285\n",
      "Batch Error : 0.0004677778633777052\n",
      "Batch Error : 0.00028602711972780526\n",
      "Época 70/150, Pérdida: 0.00352400296431934\n",
      "Época 70/150\n",
      "P= 0.6991186839012926\n",
      "R= 0.6960432695088794\n",
      "F1= 0.697523262676975\n",
      "Acc= 0.754257907542579\n",
      "Batch Error : 0.0007151595782488585\n",
      "Batch Error : 0.0010260065319016576\n",
      "Batch Error : 0.0015356197254732251\n",
      "Época 71/150, Pérdida: 0.0017974675293803088\n",
      "Época 71/150\n",
      "P= 0.7101832078228616\n",
      "R= 0.7163475443975242\n",
      "F1= 0.7130379025363351\n",
      "Acc= 0.7615571776155717\n",
      "Batch Error : 0.0003798347315751016\n",
      "Batch Error : 0.0010744687169790268\n",
      "Batch Error : 0.00016220564430113882\n",
      "Batch Error : 0.00044325177441351116\n",
      "Batch Error : 0.00035943399416282773\n",
      "Época 72/150, Pérdida: 0.0012191465436350473\n",
      "Época 72/150\n",
      "P= 0.7101832078228616\n",
      "R= 0.7163475443975242\n",
      "F1= 0.7130379025363351\n",
      "Acc= 0.7615571776155717\n",
      "Batch Error : 0.0007519734208472073\n",
      "Época 73/150, Pérdida: 0.0005448617399326458\n",
      "Época 73/150\n",
      "P= 0.7087551339156591\n",
      "R= 0.7087551339156591\n",
      "F1= 0.7087551339156591\n",
      "Acc= 0.7615571776155717\n",
      "Batch Error : 0.016040833666920662\n",
      "Batch Error : 8.435464405920357e-05\n",
      "Batch Error : 0.00031197734642773867\n",
      "Batch Error : 3.0464476367342286e-05\n",
      "Batch Error : 0.046212296932935715\n",
      "Época 74/150, Pérdida: 0.0023339189232627114\n",
      "Época 74/150\n",
      "P= 0.7107351712614871\n",
      "R= 0.7188783478914791\n",
      "F1= 0.7144052413636621\n",
      "Acc= 0.7615571776155717\n",
      "Batch Error : 6.671150185866281e-05\n",
      "Batch Error : 0.003948042169213295\n",
      "Época 75/150, Pérdida: 0.0009132975309481041\n",
      "Época 75/150\n",
      "P= 0.7081762226904735\n",
      "R= 0.717171863249841\n",
      "F1= 0.7121706221483395\n",
      "Acc= 0.7591240875912408\n",
      "Batch Error : 0.0001133902624133043\n",
      "Batch Error : 0.00033710498246364295\n",
      "Época 76/150, Pérdida: 0.0008961330175476052\n",
      "Época 76/150\n",
      "P= 0.7126099706744868\n",
      "R= 0.7264707583733441\n",
      "F1= 0.7183356643356643\n",
      "Acc= 0.7615571776155717\n",
      "Batch Error : 0.00013586091517936438\n",
      "Batch Error : 2.8811380616389215e-05\n",
      "Época 77/150, Pérdida: 0.00025607285872332605\n",
      "Época 77/150\n",
      "P= 0.702478651436176\n",
      "R= 0.7112280904726095\n",
      "F1= 0.7063558872422453\n",
      "Acc= 0.754257907542579\n",
      "Batch Error : 7.654903311049566e-05\n",
      "Batch Error : 0.00022794879623688757\n",
      "Batch Error : 0.0003383378789294511\n",
      "Época 78/150, Pérdida: 0.00035661628357800133\n",
      "Época 78/150\n",
      "P= 0.7081762226904735\n",
      "R= 0.717171863249841\n",
      "F1= 0.7121706221483395\n",
      "Acc= 0.7591240875912408\n",
      "Batch Error : 0.00013523419329430908\n",
      "Batch Error : 2.443346966174431e-05\n",
      "Batch Error : 1.2987240552320145e-05\n",
      "Época 79/150, Pérdida: 0.00010946500376497891\n",
      "Época 79/150\n",
      "P= 0.7031585023915554\n",
      "R= 0.7137588939665644\n",
      "F1= 0.7077204717479317\n",
      "Acc= 0.754257907542579\n",
      "Batch Error : 6.9034367697895505e-06\n",
      "Batch Error : 1.1187195013917517e-05\n",
      "Batch Error : 2.4617691451567225e-05\n",
      "Época 80/150, Pérdida: 0.0001075988325283106\n",
      "Época 80/150\n",
      "P= 0.7044087894795998\n",
      "R= 0.7104037716202927\n",
      "F1= 0.7071815332003419\n",
      "Acc= 0.7566909975669099\n",
      "Batch Error : 0.0001648025499889627\n",
      "Batch Error : 0.00023201340809464455\n",
      "Batch Error : 4.614882709574886e-05\n",
      "Época 81/150, Pérdida: 8.504307876639108e-05\n",
      "Época 81/150\n",
      "P= 0.6999779151943463\n",
      "R= 0.7095216058309712\n",
      "F1= 0.7041412601626016\n",
      "Acc= 0.7518248175182481\n",
      "Batch Error : 7.83640643930994e-06\n",
      "Batch Error : 1.733009412419051e-05\n",
      "Batch Error : 2.0049748854944482e-05\n",
      "Batch Error : 5.401241287472658e-05\n",
      "Época 82/150, Pérdida: 6.784394564608098e-05\n",
      "Época 82/150\n",
      "P= 0.6999779151943463\n",
      "R= 0.7095216058309712\n",
      "F1= 0.7041412601626016\n",
      "Acc= 0.7518248175182481\n",
      "Batch Error : 9.864007006399333e-05\n",
      "Batch Error : 9.83634981821524e-06\n",
      "Batch Error : 2.2507749235955998e-05\n",
      "Época 83/150, Pérdida: 0.00019704233973870627\n",
      "Época 83/150\n",
      "P= 0.6999779151943463\n",
      "R= 0.7095216058309712\n",
      "F1= 0.7041412601626016\n",
      "Acc= 0.7518248175182481\n",
      "Batch Error : 2.6917365175904706e-05\n",
      "Batch Error : 3.3707399325066945e-06\n",
      "Batch Error : 0.0006944466149434447\n",
      "Época 84/150, Pérdida: 0.00014095196481070287\n",
      "Época 84/150\n",
      "P= 0.7051556991774384\n",
      "R= 0.701987042286111\n",
      "F1= 0.703512901039807\n",
      "Acc= 0.7591240875912408\n",
      "Batch Error : 4.233580330037512e-05\n",
      "Batch Error : 0.00010419370664749295\n",
      "Batch Error : 1.8834660295397043e-05\n",
      "Época 85/150, Pérdida: 6.826188739288572e-05\n",
      "Época 85/150\n",
      "P= 0.7060118567975135\n",
      "R= 0.7070486492740209\n",
      "F1= 0.7065238558909446\n",
      "Acc= 0.7591240875912408\n",
      "Batch Error : 1.0696312529034913e-05\n",
      "Batch Error : 0.00047785777132958174\n",
      "Batch Error : 4.78483343613334e-05\n",
      "Época 86/150, Pérdida: 0.0003681646329478726\n",
      "Época 86/150\n",
      "P= 0.7070299771912676\n",
      "R= 0.7205269855961127\n",
      "F1= 0.7125874125874125\n",
      "Acc= 0.7566909975669099\n",
      "Batch Error : 5.362075171433389e-06\n",
      "Batch Error : 2.920099859693437e-06\n",
      "Batch Error : 5.9101294027641416e-05\n",
      "Época 87/150, Pérdida: 0.00011001350868621651\n",
      "Época 87/150\n",
      "P= 0.7014499837080481\n",
      "R= 0.7145832128188813\n",
      "F1= 0.7068391608391609\n",
      "Acc= 0.7518248175182481\n",
      "Batch Error : 0.00016138446517288685\n",
      "Batch Error : 0.0002755629539024085\n",
      "Época 88/150, Pérdida: 0.0001886357910875788\n",
      "Época 88/150\n",
      "P= 0.7094738276990185\n",
      "R= 0.7222334702377509\n",
      "F1= 0.7148173847221346\n",
      "Acc= 0.7591240875912408\n",
      "Batch Error : 4.8918054744717665e-06\n",
      "Batch Error : 5.501481064129621e-05\n",
      "Época 89/150, Pérdida: 3.420968612866498e-05\n",
      "Época 89/150\n",
      "P= 0.7107351712614871\n",
      "R= 0.7188783478914791\n",
      "F1= 0.7144052413636621\n",
      "Acc= 0.7615571776155717\n",
      "Batch Error : 0.00012016667460557073\n",
      "Batch Error : 1.8556163468019804e-06\n",
      "Batch Error : 2.250440502393758e-06\n",
      "Batch Error : 0.0001028768892865628\n",
      "Época 90/150, Pérdida: 0.00025074321560372606\n",
      "Época 90/150\n",
      "P= 0.709192439862543\n",
      "R= 0.7112859374096141\n",
      "F1= 0.7102135374697824\n",
      "Acc= 0.7615571776155717\n",
      "Batch Error : 3.893286702805199e-06\n",
      "Época 91/150, Pérdida: 0.0018874925468159336\n",
      "Época 91/150\n",
      "P= 0.709192439862543\n",
      "R= 0.7112859374096141\n",
      "F1= 0.7102135374697824\n",
      "Acc= 0.7615571776155717\n",
      "Batch Error : 5.003413753001951e-05\n",
      "Batch Error : 3.0927412808523513e-06\n",
      "Batch Error : 3.916913556167856e-05\n",
      "Época 92/150, Pérdida: 0.0005525432799976411\n",
      "Época 92/150\n",
      "P= 0.7046167577216422\n",
      "R= 0.7188205009544745\n",
      "F1= 0.7103634498782454\n",
      "Acc= 0.754257907542579\n",
      "Batch Error : 0.0006389281479641795\n",
      "Batch Error : 1.7923848645295948e-05\n",
      "Batch Error : 0.0005039895768277347\n",
      "Batch Error : 3.671849117381498e-05\n",
      "Época 93/150, Pérdida: 0.0023417083679744574\n",
      "Época 93/150\n",
      "P= 0.7016107702073635\n",
      "R= 0.720469138659108\n",
      "F1= 0.7084604524637581\n",
      "Acc= 0.7493917274939172\n",
      "Época 94/150, Pérdida: 0.0011000566430774252\n",
      "Época 94/150\n",
      "P= 0.7046167577216422\n",
      "R= 0.7188205009544745\n",
      "F1= 0.7103634498782454\n",
      "Acc= 0.754257907542579\n",
      "Batch Error : 2.329567178094294e-05\n",
      "Época 95/150, Pérdida: 0.0006561798746149399\n",
      "Época 95/150\n",
      "P= 0.7109098228663446\n",
      "R= 0.727295077225661\n",
      "F1= 0.7173530984946894\n",
      "Acc= 0.7591240875912408\n",
      "Batch Error : 1.952432830876205e-05\n",
      "Época 96/150, Pérdida: 0.001515261170699636\n",
      "Época 96/150\n",
      "P= 0.6967810801818787\n",
      "R= 0.705284317695378\n",
      "F1= 0.7005411523361511\n",
      "Acc= 0.7493917274939172\n",
      "Batch Error : 0.02012631483376026\n",
      "Batch Error : 0.0010882321512326598\n",
      "Batch Error : 1.6371282981708646e-05\n",
      "Época 97/150, Pérdida: 0.0026515436301851564\n",
      "Época 97/150\n",
      "P= 0.7150763358778626\n",
      "R= 0.7281772430149823\n",
      "F1= 0.720578649677243\n",
      "Acc= 0.7639902676399026\n",
      "Batch Error : 0.07712719589471817\n",
      "Batch Error : 0.010994273237884045\n",
      "Época 98/150, Pérdida: 0.005817480117959098\n",
      "Época 98/150\n",
      "P= 0.713873793944771\n",
      "R= 0.7231156360270723\n",
      "F1= 0.7179853570544336\n",
      "Acc= 0.7639902676399026\n",
      "Batch Error : 0.0005725292721763253\n",
      "Batch Error : 0.03449099883437157\n",
      "Época 99/150, Pérdida: 0.007227975264774206\n",
      "Época 99/150\n",
      "P= 0.7038713195201745\n",
      "R= 0.7162896974605195\n",
      "F1= 0.7090561197670262\n",
      "Acc= 0.754257907542579\n",
      "Batch Error : 0.001255964394658804\n",
      "Batch Error : 0.048612844198942184\n",
      "Batch Error : 0.015102856792509556\n",
      "Batch Error : 0.022321343421936035\n",
      "Época 100/150, Pérdida: 0.010704186923186202\n",
      "Época 100/150\n",
      "P= 0.6975094837539172\n",
      "R= 0.7078151211893331\n",
      "F1= 0.7019327583171977\n",
      "Acc= 0.7493917274939172\n",
      "Batch Error : 0.000167816921020858\n",
      "Batch Error : 0.002734565641731024\n",
      "Batch Error : 0.015425422228872776\n",
      "Batch Error : 0.06278979033231735\n",
      "Época 101/150, Pérdida: 0.019007930068694584\n",
      "Época 101/150\n",
      "P= 0.7062043795620438\n",
      "R= 0.7238821079423845\n",
      "F1= 0.712895528581803\n",
      "Acc= 0.754257907542579\n",
      "Batch Error : 0.007349116262048483\n",
      "Batch Error : 0.032109737396240234\n",
      "Batch Error : 0.002941042184829712\n",
      "Época 102/150, Pérdida: 0.030845894827507436\n",
      "Época 102/150\n",
      "P= 0.6999779151943463\n",
      "R= 0.7095216058309712\n",
      "F1= 0.7041412601626016\n",
      "Acc= 0.7518248175182481\n",
      "Batch Error : 0.005678887479007244\n",
      "Batch Error : 0.012528774328529835\n",
      "Batch Error : 0.014281807467341423\n",
      "Batch Error : 0.002479394432157278\n",
      "Batch Error : 0.01748618856072426\n",
      "Época 103/150, Pérdida: 0.017107330953124267\n",
      "Época 103/150\n",
      "P= 0.6935672514619884\n",
      "R= 0.7010470295597848\n",
      "F1= 0.6969198479777639\n",
      "Acc= 0.7469586374695864\n",
      "Batch Error : 0.0028478417079895735\n",
      "Batch Error : 0.017632149159908295\n",
      "Batch Error : 0.007692138198763132\n",
      "Época 104/150, Pérdida: 0.009018077077504632\n",
      "Época 104/150\n",
      "P= 0.6975534759358288\n",
      "R= 0.7137010470295597\n",
      "F1= 0.7037262947765333\n",
      "Acc= 0.7469586374695864\n",
      "Batch Error : 0.0005797417834401131\n",
      "Batch Error : 0.0016144643304869533\n",
      "Batch Error : 0.0006396851385943592\n",
      "Época 105/150, Pérdida: 0.005544400148837354\n",
      "Época 105/150\n",
      "P= 0.6974226804123711\n",
      "R= 0.6993983918551513\n",
      "F1= 0.698385518590998\n",
      "Acc= 0.7518248175182481\n",
      "Batch Error : 0.012837947346270084\n",
      "Batch Error : 0.0007308396161533892\n",
      "Batch Error : 6.953161937417462e-05\n",
      "Batch Error : 0.0015805070288479328\n",
      "Batch Error : 0.00013138588110450655\n",
      "Batch Error : 7.857604214223102e-05\n",
      "Batch Error : 0.024779509752988815\n",
      "Batch Error : 0.0007240410195663571\n",
      "Batch Error : 5.247615263215266e-05\n",
      "Época 106/150, Pérdida: 0.004136753627570779\n",
      "Época 106/150\n",
      "P= 0.7075804195804196\n",
      "R= 0.7146410597558859\n",
      "F1= 0.7108040683170216\n",
      "Acc= 0.7591240875912408\n",
      "Batch Error : 0.014848018996417522\n",
      "Batch Error : 0.0007876066374592483\n",
      "Batch Error : 0.007418094668537378\n",
      "Batch Error : 6.368999311234802e-05\n",
      "Batch Error : 0.0006694881594739854\n",
      "Época 107/150, Pérdida: 0.0027094493982139254\n",
      "Época 107/150\n",
      "P= 0.713873793944771\n",
      "R= 0.7231156360270723\n",
      "F1= 0.7179853570544336\n",
      "Acc= 0.7639902676399026\n",
      "Batch Error : 0.0002763975062407553\n",
      "Batch Error : 0.00014369380369316787\n",
      "Época 108/150, Pérdida: 0.003842219735564993\n",
      "Época 108/150\n",
      "P= 0.7088075210291935\n",
      "R= 0.7197026667437959\n",
      "F1= 0.7135081851786658\n",
      "Acc= 0.7591240875912408\n",
      "Batch Error : 0.00013288987975101918\n",
      "Batch Error : 8.542211435269564e-05\n",
      "Época 109/150, Pérdida: 0.001072115301087314\n",
      "Época 109/150\n",
      "P= 0.7154971921266096\n",
      "R= 0.7197605136808006\n",
      "F1= 0.7175257731958763\n",
      "Acc= 0.7664233576642335\n",
      "Batch Error : 0.005562099162489176\n",
      "Época 110/150, Pérdida: 0.004106963204102267\n",
      "Época 110/150\n",
      "P= 0.7164578111946533\n",
      "R= 0.7248221206687107\n",
      "F1= 0.7202337058256283\n",
      "Acc= 0.7664233576642335\n",
      "Batch Error : 2.5332070435979404e-05\n",
      "Batch Error : 0.029225356876850128\n",
      "Batch Error : 0.00018603407079353929\n",
      "Época 111/150, Pérdida: 0.007561891352891288\n",
      "Época 111/150\n",
      "P= 0.7113239840989399\n",
      "R= 0.7214091513854342\n",
      "F1= 0.7157435636856369\n",
      "Acc= 0.7615571776155717\n",
      "Batch Error : 0.0002307999093318358\n",
      "Batch Error : 0.00016272602078970522\n",
      "Batch Error : 0.00014200765872374177\n",
      "Época 112/150, Pérdida: 0.004559229862934444\n",
      "Época 112/150\n",
      "P= 0.720642679470122\n",
      "R= 0.720642679470122\n",
      "F1= 0.720642679470122\n",
      "Acc= 0.7712895377128953\n",
      "Batch Error : 0.0004053223819937557\n",
      "Batch Error : 8.307046664413065e-05\n",
      "Época 113/150, Pérdida: 0.0017491677350210074\n",
      "Época 113/150\n",
      "P= 0.7012195121951219\n",
      "R= 0.7061664834846995\n",
      "F1= 0.7035373265438756\n",
      "Acc= 0.754257907542579\n",
      "Batch Error : 0.0002184638287872076\n",
      "Batch Error : 9.770312317414209e-05\n",
      "Batch Error : 0.0032760200556367636\n",
      "Época 114/150, Pérdida: 0.001804179712876405\n",
      "Época 114/150\n",
      "P= 0.7115384615384616\n",
      "R= 0.7104616185572974\n",
      "F1= 0.7109935119069194\n",
      "Acc= 0.7639902676399026\n",
      "Batch Error : 0.002661283826455474\n",
      "Batch Error : 3.873102832585573e-05\n",
      "Batch Error : 0.0021098600700497627\n",
      "Batch Error : 0.00012470403453335166\n",
      "Batch Error : 7.475560414604843e-05\n",
      "Época 115/150, Pérdida: 0.0010270610928900764\n",
      "Época 115/150\n",
      "P= 0.7101832078228616\n",
      "R= 0.7163475443975242\n",
      "F1= 0.7130379025363351\n",
      "Acc= 0.7615571776155717\n",
      "Batch Error : 0.0003359593392815441\n",
      "Batch Error : 5.657688598148525e-05\n",
      "Época 116/150, Pérdida: 0.0001269173033698468\n",
      "Época 116/150\n",
      "P= 0.7150773195876289\n",
      "R= 0.7172297101868456\n",
      "F1= 0.7161275469091746\n",
      "Acc= 0.7664233576642335\n",
      "Batch Error : 0.0001047061086865142\n",
      "Época 117/150, Pérdida: 0.005830250237162043\n",
      "Época 117/150\n",
      "P= 0.7119490829455242\n",
      "R= 0.7239399548793891\n",
      "F1= 0.7170535011801731\n",
      "Acc= 0.7615571776155717\n",
      "Batch Error : 0.00026927367434836924\n",
      "Batch Error : 0.0001639990950934589\n",
      "Época 118/150, Pérdida: 0.002577213967328887\n",
      "Época 118/150\n",
      "P= 0.7023524254821741\n",
      "R= 0.7002805576444727\n",
      "F1= 0.7012907727193441\n",
      "Acc= 0.7566909975669099\n",
      "Batch Error : 0.004068652167916298\n",
      "Batch Error : 0.005715996492654085\n",
      "Época 119/150, Pérdida: 0.002966275013210995\n",
      "Época 119/150\n",
      "P= 0.7083576855639977\n",
      "R= 0.7062243304217042\n",
      "F1= 0.7072649572649573\n",
      "Acc= 0.7615571776155717\n",
      "Batch Error : 4.6971195843070745e-05\n",
      "Batch Error : 0.0016521374927833676\n",
      "Batch Error : 0.0004957919591106474\n",
      "Batch Error : 0.0030137300491333008\n",
      "Batch Error : 5.0605274736881256e-05\n",
      "Época 120/150, Pérdida: 0.004081595289100169\n",
      "Época 120/150\n",
      "P= 0.7018321678321677\n",
      "R= 0.7086972869786545\n",
      "F1= 0.70496172626282\n",
      "Acc= 0.754257907542579\n",
      "Batch Error : 0.0001502560917288065\n",
      "Batch Error : 0.00048646843060851097\n",
      "Batch Error : 5.7048629969358444e-05\n",
      "Época 121/150, Pérdida: 0.005022310371588964\n",
      "Época 121/150\n",
      "P= 0.6920588235294117\n",
      "R= 0.7077572742523284\n",
      "F1= 0.6980287235222358\n",
      "Acc= 0.7420924574209246\n",
      "Época 122/150, Pérdida: 0.0032121093640382933\n",
      "Época 122/150\n",
      "P= 0.7209621993127148\n",
      "R= 0.723173482964077\n",
      "F1= 0.7220415563485668\n",
      "Acc= 0.7712895377128953\n",
      "Batch Error : 7.092899613780901e-05\n",
      "Batch Error : 0.00017892522737383842\n",
      "Batch Error : 2.712828245421406e-05\n",
      "Batch Error : 0.00021275340986903757\n",
      "Época 123/150, Pérdida: 0.002684601328430039\n",
      "Época 123/150\n",
      "P= 0.700641208321459\n",
      "R= 0.7036356799907445\n",
      "F1= 0.7020820026267252\n",
      "Acc= 0.754257907542579\n",
      "Batch Error : 0.0005188501090742648\n",
      "Batch Error : 0.0001874533627415076\n",
      "Batch Error : 0.0007418531458824873\n",
      "Batch Error : 2.3835882529965602e-05\n",
      "Batch Error : 0.00015898505807854235\n",
      "Época 124/150, Pérdida: 0.002722091216567386\n",
      "Época 124/150\n",
      "P= 0.7056509496466431\n",
      "R= 0.7154653786082027\n",
      "F1= 0.7099424119241192\n",
      "Acc= 0.7566909975669099\n",
      "Batch Error : 0.0004434908623807132\n",
      "Batch Error : 0.00015771275502629578\n",
      "Época 125/150, Pérdida: 0.0040220272597347\n",
      "Época 125/150\n",
      "P= 0.6998792270531401\n",
      "R= 0.715407531671198\n",
      "F1= 0.705933021666192\n",
      "Acc= 0.7493917274939172\n",
      "Batch Error : 0.026163101196289062\n",
      "Batch Error : 0.00013469390978571028\n",
      "Época 126/150, Pérdida: 0.01167718609965583\n",
      "Época 126/150\n",
      "P= 0.7088075210291935\n",
      "R= 0.7197026667437959\n",
      "F1= 0.7135081851786658\n",
      "Acc= 0.7591240875912408\n",
      "Batch Error : 0.0021822883281856775\n",
      "Batch Error : 0.0022283843718469143\n",
      "Época 127/150, Pérdida: 0.0075163835586110886\n",
      "Época 127/150\n",
      "P= 0.7028113611384277\n",
      "R= 0.7028113611384277\n",
      "F1= 0.7028113611384277\n",
      "Acc= 0.7566909975669099\n",
      "Batch Error : 0.003410506062209606\n",
      "Época 128/150, Pérdida: 0.005776957725174725\n",
      "Época 128/150\n",
      "P= 0.6992898913951546\n",
      "R= 0.7069908023370162\n",
      "F1= 0.70274831243973\n",
      "Acc= 0.7518248175182481\n",
      "Batch Error : 0.004054537974298\n",
      "Época 129/150, Pérdida: 0.004693417067348241\n",
      "Época 129/150\n",
      "P= 0.720642679470122\n",
      "R= 0.720642679470122\n",
      "F1= 0.720642679470122\n",
      "Acc= 0.7712895377128953\n",
      "Batch Error : 2.596950434963219e-05\n",
      "Batch Error : 3.521912731230259e-05\n",
      "Batch Error : 0.0006211014115251601\n",
      "Época 130/150, Pérdida: 0.0015680438829239675\n",
      "Época 130/150\n",
      "P= 0.7140705298600035\n",
      "R= 0.7096372997049807\n",
      "F1= 0.7117475160724722\n",
      "Acc= 0.7664233576642335\n",
      "Batch Error : 3.258521974203177e-05\n",
      "Batch Error : 0.0004871933488175273\n",
      "Batch Error : 0.0020070255268365145\n",
      "Época 131/150, Pérdida: 0.002413129579257782\n",
      "Época 131/150\n",
      "P= 0.7260344306855935\n",
      "R= 0.7164632382715335\n",
      "F1= 0.7208045365940103\n",
      "Acc= 0.7761557177615572\n",
      "Batch Error : 0.0002349976566620171\n",
      "Batch Error : 0.006215524394065142\n",
      "Batch Error : 2.322423824807629e-05\n",
      "Época 132/150, Pérdida: 0.0014213803346812147\n",
      "Época 132/150\n",
      "P= 0.720642679470122\n",
      "R= 0.720642679470122\n",
      "F1= 0.720642679470122\n",
      "Acc= 0.7712895377128953\n",
      "Época 133/150, Pérdida: 0.00040334644231263846\n",
      "Época 133/150\n",
      "P= 0.7217320445093852\n",
      "R= 0.728235089951987\n",
      "F1= 0.7247506412083214\n",
      "Acc= 0.7712895377128953\n",
      "Batch Error : 9.331733963335864e-06\n",
      "Batch Error : 9.414108717464842e-06\n",
      "Batch Error : 0.0003121158224530518\n",
      "Época 134/150, Pérdida: 0.0008291738727695607\n",
      "Época 134/150\n",
      "P= 0.7260959149546107\n",
      "R= 0.7189940417654885\n",
      "F1= 0.7222972972972973\n",
      "Acc= 0.7761557177615572\n",
      "Batch Error : 6.18051035417011e-06\n",
      "Batch Error : 2.5073140932363458e-05\n",
      "Batch Error : 5.783455776509072e-07\n",
      "Batch Error : 3.512653347570449e-05\n",
      "Batch Error : 6.753666184522444e-06\n",
      "Época 135/150, Pérdida: 0.0017239171969726126\n",
      "Época 135/150\n",
      "P= 0.7291441441441442\n",
      "R= 0.7207005264071267\n",
      "F1= 0.7245815445112926\n",
      "Acc= 0.7785888077858881\n",
      "Batch Error : 3.841765646939166e-05\n",
      "Batch Error : 0.0048324670642614365\n",
      "Batch Error : 4.221341441734694e-05\n",
      "Batch Error : 1.884344055724796e-05\n",
      "Época 136/150, Pérdida: 0.0052937371928206195\n",
      "Época 136/150\n",
      "P= 0.7418378012788982\n",
      "R= 0.7275264649736797\n",
      "F1= 0.7338023450586264\n",
      "Acc= 0.7883211678832117\n",
      "Batch Error : 6.643168035225244e-06\n",
      "Batch Error : 3.582901626941748e-05\n",
      "Batch Error : 0.0077769276686012745\n",
      "Batch Error : 0.10476615279912949\n",
      "Época 137/150, Pérdida: 0.017856273040165592\n",
      "Época 137/150\n",
      "P= 0.7234868306296878\n",
      "R= 0.7223491641117603\n",
      "F1= 0.7229113052303454\n",
      "Acc= 0.7737226277372263\n",
      "Batch Error : 0.0370786190032959\n",
      "Batch Error : 0.0001688318734522909\n",
      "Batch Error : 0.0007696609827689826\n",
      "Batch Error : 0.05714404955506325\n",
      "Época 138/150, Pérdida: 0.027325161741263683\n",
      "Época 138/150\n",
      "P= 0.7159576261661234\n",
      "R= 0.7222913171747556\n",
      "F1= 0.7188942718723283\n",
      "Acc= 0.7664233576642335\n",
      "Batch Error : 0.016688166186213493\n",
      "Batch Error : 0.007826808840036392\n",
      "Batch Error : 0.002168301958590746\n",
      "Época 139/150, Pérdida: 0.010127362050517494\n",
      "Época 139/150\n",
      "P= 0.7209621993127148\n",
      "R= 0.723173482964077\n",
      "F1= 0.7220415563485668\n",
      "Acc= 0.7712895377128953\n",
      "Batch Error : 8.939446706790477e-05\n",
      "Batch Error : 0.0005233470583334565\n",
      "Batch Error : 0.00023140139819588512\n",
      "Época 140/150, Pérdida: 0.008716770382181556\n",
      "Época 140/150\n",
      "P= 0.7237538851156902\n",
      "R= 0.7248799676057153\n",
      "F1= 0.7243102888672509\n",
      "Acc= 0.7737226277372263\n",
      "Época 141/150, Pérdida: 0.005327821818731348\n",
      "Época 141/150\n",
      "P= 0.7413777908343127\n",
      "R= 0.7376496789494996\n",
      "F1= 0.7394507312168002\n",
      "Acc= 0.7883211678832117\n",
      "Batch Error : 0.0007768387440592051\n",
      "Batch Error : 0.0001380289759254083\n",
      "Época 142/150, Pérdida: 0.006926878812699779\n",
      "Época 142/150\n",
      "P= 0.7217320445093852\n",
      "R= 0.728235089951987\n",
      "F1= 0.7247506412083214\n",
      "Acc= 0.7712895377128953\n",
      "Batch Error : 0.00028476648731157184\n",
      "Batch Error : 0.00010130533337360248\n",
      "Época 143/150, Pérdida: 0.002512756925641262\n",
      "Época 143/150\n",
      "P= 0.7383839859731152\n",
      "R= 0.7359431943078614\n",
      "F1= 0.7371358799930228\n",
      "Acc= 0.7858880778588808\n",
      "Batch Error : 0.0004883635556325316\n",
      "Batch Error : 1.5828783944016322e-05\n",
      "Batch Error : 0.00010887515963986516\n",
      "Batch Error : 4.630220792023465e-05\n",
      "Época 144/150, Pérdida: 0.0006836608950709041\n",
      "Época 144/150\n",
      "P= 0.7444178628389155\n",
      "R= 0.7393561635911379\n",
      "F1= 0.7417738164815897\n",
      "Acc= 0.7907542579075426\n",
      "Batch Error : 8.521440031472594e-05\n",
      "Batch Error : 0.0002641071623656899\n",
      "Batch Error : 0.004053269047290087\n",
      "Batch Error : 0.009293314069509506\n",
      "Época 145/150, Pérdida: 0.0022803407403420477\n",
      "Época 145/150\n",
      "P= 0.7327319587628867\n",
      "R= 0.7350610285185399\n",
      "F1= 0.7338695752273512\n",
      "Acc= 0.781021897810219\n",
      "Batch Error : 6.881625449750572e-05\n",
      "Época 146/150, Pérdida: 0.0009361589869387962\n",
      "Época 146/150\n",
      "P= 0.7299230550014248\n",
      "R= 0.7333545438769017\n",
      "F1= 0.7315788340498217\n",
      "Acc= 0.7785888077858881\n",
      "Batch Error : 5.989212695567403e-06\n",
      "Batch Error : 4.187459853710607e-05\n",
      "Batch Error : 2.610868978081271e-05\n",
      "Época 147/150, Pérdida: 0.0008705376905850401\n",
      "Época 147/150\n",
      "P= 0.7237538851156902\n",
      "R= 0.7248799676057153\n",
      "F1= 0.7243102888672509\n",
      "Acc= 0.7737226277372263\n",
      "Batch Error : 6.857854896225035e-05\n",
      "Época 148/150, Pérdida: 0.0010492223272947363\n",
      "Época 148/150\n",
      "P= 0.7299230550014248\n",
      "R= 0.7333545438769017\n",
      "F1= 0.7315788340498217\n",
      "Acc= 0.7785888077858881\n",
      "Batch Error : 4.626406280294759e-06\n",
      "Batch Error : 0.0002091567439492792\n",
      "Batch Error : 2.9458400604198687e-05\n",
      "Batch Error : 8.034550774027593e-06\n",
      "Época 149/150, Pérdida: 0.000339297456717163\n",
      "Época 149/150\n",
      "P= 0.7299230550014248\n",
      "R= 0.7333545438769017\n",
      "F1= 0.7315788340498217\n",
      "Acc= 0.7785888077858881\n",
      "Batch Error : 0.0001416571467416361\n",
      "Batch Error : 3.6859262309008045e-06\n",
      "Época 150/150, Pérdida: 0.00013734361317770452\n",
      "Época 150/150\n",
      "P= 0.7453621908127208\n",
      "R= 0.7570717880488228\n",
      "F1= 0.7505504742547425\n",
      "Acc= 0.7907542579075426\n",
      "tensor([0, 1, 1,  ..., 0, 1, 0])\n",
      "[[193 103]\n",
      " [114 617]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6287    0.6520    0.6401       296\n",
      "           1     0.8569    0.8440    0.8504       731\n",
      "\n",
      "    accuracy                         0.7887      1027\n",
      "   macro avg     0.7428    0.7480    0.7453      1027\n",
      "weighted avg     0.7912    0.7887    0.7898      1027\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Main\"\"\"\n",
    "\"\"\"Recopilamos las funciones para crear poder entrenar nuestra red neuronal\"\"\"\n",
    "\n",
    "# Leemos los datos del dataset.\n",
    "X, Y = read_dataset()\n",
    "\n",
    "# Dividimos nuestro dataset.\n",
    "Y_encoded = encode_labels(Y=Y)\n",
    "\n",
    "data_list_train, data_list_test = dataset_div(X,Y_encoded)\n",
    "\n",
    "#Separamos nuestros distintos datos\n",
    "X_train = data_list_train[0]\n",
    "X_val = data_list_train[1]\n",
    "Y_train = data_list_train[2]\n",
    "Y_val = data_list_train[3]\n",
    "\n",
    "X_test = data_list_test[0]\n",
    "Y_test = data_list_test[1]\n",
    "   \n",
    "\n",
    "# Vectorizamos nuestro subconjunto de data set (Y al mismo tiempo lo normalizamos y convertimos en matriz)\n",
    "X_train_tfidf, X_val_tfidf, vec_tfidf= matriz_tfidfVectorizer(X_train=X_train,X_val=X_val)\n",
    "\n",
    "\n",
    "# Sacamos la codificacion onehot  \n",
    "Y_train_one_hot, Y_test_one_hot, Y_val_one_hot  = salida_onehot(Y_train=Y_train, Y_test=Y_test, Y_val=Y_val, NUM_CLASSES = 2) \n",
    "\n",
    "# Entrenamos nuestra red neuronal\n",
    "model = train_red_neuronal(X_train_tfidf=X_train_tfidf,X_val_tfidf=X_val_tfidf,output_size=2,epochs=150,learning_rate=0.01,batch_size=128)\n",
    "\n",
    "# Imprimimos nuetsra evaluación\n",
    "evaluacion(X_test=X_test, vec_tfidf=vec_tfidf, Y_test=Y_test, model=model)\n",
    " \n",
    "\n",
    "   \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RNA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
